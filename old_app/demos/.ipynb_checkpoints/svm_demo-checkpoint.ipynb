{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ee0635-c0de-43d1-b795-4437c44ed754",
   "metadata": {},
   "source": [
    "## SIIM Data Covid-19 SVM classifier\n",
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3afcf9d8-304e-420b-b146-6484220986e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default config\n",
    "model_name = \"ResNet50\"\n",
    "learning_rate = 0.0001\n",
    "min_learning_rate = 1e-8\n",
    "batch_size = 25\n",
    "epochs = 1\n",
    "verbose = 1\n",
    "img_process_function = \"equalize_adapthist\"\n",
    "isKaggleData = False\n",
    "classification_type = \"binary\"\n",
    "classifier = \"svm\"\n",
    "\n",
    "train_num = 10\n",
    "val_num = 2\n",
    "show_cv_scores = False\n",
    "feature_number = 128\n",
    "\n",
    "use_fine_tuning = False\n",
    "use_chex_weights = True\n",
    "\n",
    "libraries = [\"pandas\",\"numpy\",\"sklearn\",\"tensorflow\",\"keras\",\"skimage\",\"matplotlib\",\"seaborn\"]\n",
    "show_versions = True\n",
    "svm_hyp_search = \"grid\"\n",
    "\n",
    "show_model_summary = False\n",
    "save_weights = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940df0b8-6216-4555-b552-f7230b33c171",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb1aaa7-59d2-495f-afbb-3191d8fbd84d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from skimage import exposure\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint,  EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications import VGG16, VGG19, InceptionV3, NASNetMobile, NASNetLarge, DenseNet121, ResNet50, Xception, InceptionResNetV2\n",
    "\n",
    "import importlib\n",
    "from skimage import exposure\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb37226f-4eaf-4d67-9d33-ff3fbaf04de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.2.4\n",
      "numpy version: 1.20.1\n",
      "sklearn version: 0.24.1\n",
      "tensorflow version: 2.3.0\n",
      "keras version: 2.4.3\n",
      "skimage version: 0.18.1\n",
      "matplotlib version: 3.3.4\n",
      "seaborn version: 0.11.1\n"
     ]
    }
   ],
   "source": [
    "def display_versions(libraries = None):\n",
    "    \n",
    "    from importlib import import_module\n",
    "    \n",
    "    for library in libraries:\n",
    "        print(f\"{library} version: {import_module(library).__version__}\")\n",
    "\n",
    "if show_versions:\n",
    "    display_versions(libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f649799-417e-4b5d-a534-758efd9468ab",
   "metadata": {},
   "source": [
    "#### Transfer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc5133d-b708-49bc-94c4-21e24e11eb66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, VGG19, InceptionV3, NASNetMobile, NASNetLarge, DenseNet121, ResNet50, Xception, InceptionResNetV2\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    \n",
    "    models_ = dict(\n",
    "                    VGG16 = dict(\n",
    "                        input_shape = (224,224,3),\n",
    "                        module_name = \"vgg16\",\n",
    "                        last_conv_layer = \"block5_conv3\",\n",
    "                    ),\n",
    "                    VGG19 = dict(\n",
    "                        input_shape = (224,224,3),\n",
    "                        module_name = \"vgg19\",\n",
    "                        last_conv_layer = \"block5_conv4\",\n",
    "                    ),\n",
    "                    # this is used for ChexNet\n",
    "                    DenseNet121=dict(\n",
    "                        input_shape=(224, 224, 3),\n",
    "                        module_name=\"densenet\",\n",
    "                        last_conv_layer=\"conv5_block16_concat\",\n",
    "                    ),\n",
    "                    ResNet50=dict(\n",
    "                        input_shape=(224, 224, 3),\n",
    "                        module_name=\"resnet50\",\n",
    "                        last_conv_layer=\"conv5_block3_out\",\n",
    "                    ),\n",
    "                    InceptionV3=dict(\n",
    "                        input_shape=(299, 299, 3),\n",
    "                        module_name=\"inception_v3\",\n",
    "                        last_conv_layer=\"mixed10\",\n",
    "                    ),\n",
    "                    InceptionResNetV2=dict(\n",
    "                        input_shape=(299, 299, 3),\n",
    "                        module_name=\"inception_resnet_v2\",\n",
    "                        last_conv_layer=\"conv_7b_bn\",\n",
    "                    ),\n",
    "                    NASNetMobile=dict(\n",
    "                        input_shape=(224, 224, 3),\n",
    "                        module_name=\"nasnet\",\n",
    "                        last_conv_layer=\"normal_concat_12\",\n",
    "                    ),\n",
    "                    NASNetLarge=dict(\n",
    "                        input_shape=(331, 331, 3),\n",
    "                        module_name=\"nasnet\",\n",
    "                        last_conv_layer=\"normal_concat_18\",\n",
    "                    ),\n",
    "                    Xception=dict(\n",
    "                        input_shape=(299, 299, 3),\n",
    "                        module_name=\"xception\",\n",
    "                        last_conv_layer=\"block14_sepconv2_act\",\n",
    "                    ),\n",
    "                \n",
    "                )\n",
    "    \n",
    "    return models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca22c001-0526-473a-b17a-91396bbb818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ = get_models()\n",
    "input_shape = models_[model_name][\"input_shape\"]\n",
    "img_size = input_shape[0]\n",
    "\n",
    "\n",
    "if isKaggleData:\n",
    "    data, img_dir = prepare_data_for_kaggle()\n",
    "else:\n",
    "    data = pd.read_csv(\"../train_data.csv\")\n",
    "    img_dir = \"../images/train\"\n",
    "    \n",
    "df_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f771ca7-465b-401f-841a-7b8e5f3b4bad",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f78b9d0c-54a5-48c2-989f-16bd396f9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop images from dataframe not in images directory\n",
    "files = os.listdir(\"../images/train\")\n",
    "\n",
    "not_in_files_index = []\n",
    "\n",
    "for file_id in df_data.id:\n",
    "    if file_id in files:\n",
    "        continue\n",
    "    else:\n",
    "        not_in_files_index.append(df_data[df_data[\"id\"] == file_id].index[0])\n",
    "        \n",
    "df_data = df_data.drop(not_in_files_index, axis = 0)\n",
    "\n",
    "# drop images that have unclear view\n",
    "drop_df = pd.read_excel(\"../dropped_image_IDs.xlsx\") + \".jpg\"\n",
    "\n",
    "drop_index = []\n",
    "for row in drop_df.values:\n",
    "    drop_index.append(df_data[df_data[\"id\"] == row[0]].index[0])\n",
    "    \n",
    "df_data = df_data.drop(drop_index, axis = 0)\n",
    "\n",
    "# splitting images train and test\n",
    "df_train = df_data.iloc[:5000]\n",
    "df_test = df_data.iloc[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a3f3e-86db-46ce-b6f0-c64187dc66a9",
   "metadata": {},
   "source": [
    "#### Image Generators for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bb5019ad-f74d-47ce-b77b-3a1d46fbcf03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4250 validated image filenames belonging to 2 classes.\n",
      "Found 750 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "def generate_images_for_model_training(classifier, classification_type, img_process_function, df_train, df_test, img_dir, img_size, batch_size, validation_split = 0.15):\n",
    "    \n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    \n",
    "    from skimage import exposure\n",
    "    \n",
    "    # Defined image preprocessing functions\n",
    "\n",
    "    def preprocess_function(img):\n",
    "        \n",
    "        if img_process_function == \"equalize_adapthist\":\n",
    "            img = exposure.equalize_adapthist(img/255, clip_limit=0.03, kernel_size=24)\n",
    "        elif img_process_function == \"equalize_hist\":\n",
    "            img = exposure.equalize_hist(img/255, clip_limit=0.03, kernel_size=24)\n",
    "        elif img_process_function == \"rescale_intensity\":\n",
    "            img = exposure.rescale_intensity(img/255, clip_limit=0.03, kernel_size=24)\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    if classification_type == \"binary\":\n",
    "        y_col = \"image_label\"\n",
    "    else:\n",
    "        y_col = \"study_label\"\n",
    "    \n",
    "    \n",
    "    image_generator_train = ImageDataGenerator(\n",
    "                    featurewise_center=False,\n",
    "                    samplewise_center=False,\n",
    "                    featurewise_std_normalization=False,\n",
    "                    samplewise_std_normalization=False,\n",
    "                    zca_epsilon=1e-06,\n",
    "                    zca_whitening=False,\n",
    "                    width_shift_range=0.0,\n",
    "                    height_shift_range=0.0,\n",
    "                    brightness_range=[0.8, 1.1],\n",
    "                    shear_range=0.1,\n",
    "                    zoom_range=0.0,\n",
    "                    channel_shift_range=0.0,\n",
    "                    cval=0.0,\n",
    "                    horizontal_flip=False,\n",
    "                    vertical_flip=False,\n",
    "                    rescale=None,\n",
    "                    rotation_range=20,\n",
    "                    preprocessing_function=preprocess_function,\n",
    "                    validation_split=validation_split)\n",
    "        \n",
    "    image_generator_valid = ImageDataGenerator(validation_split=validation_split,\n",
    "                                               preprocessing_function=preprocess_function)\n",
    "      \n",
    "\n",
    "    train_generator = image_generator_train.flow_from_dataframe(\n",
    "                dataframe = df_train,\n",
    "                directory=img_dir,\n",
    "                x_col = 'id',\n",
    "                y_col =  y_col,  \n",
    "                target_size=(img_size, img_size),\n",
    "                batch_size=batch_size,\n",
    "                subset='training', \n",
    "                seed = 42, \n",
    "                class_mode = \"categorical\") \n",
    "        \n",
    "    valid_generator = image_generator_valid.flow_from_dataframe(\n",
    "            dataframe = df_train,\n",
    "            directory=img_dir,\n",
    "            x_col = 'id',\n",
    "            y_col = y_col,\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            subset='validation', \n",
    "            shuffle=False,  \n",
    "            seed=42, \n",
    "            class_mode = \"categorical\")\n",
    "    \n",
    "    return train_generator, valid_generator\n",
    "\n",
    "train_generator, valid_generator = generate_images_for_model_training( classifier = classifier, \n",
    "                                                                       classification_type = classification_type, \n",
    "                                                                       img_process_function = img_process_function, \n",
    "                                                                       df_train = df_train, \n",
    "                                                                       df_test = df_test, \n",
    "                                                                       img_dir = img_dir, \n",
    "                                                                       img_size = img_size, \n",
    "                                                                       batch_size = batch_size, \n",
    "                                                                       validation_split = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a1cbc-c9b2-41d8-aa44-f7c83ab1364f",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eca7506a-5eed-459f-976d-73f9b3e6b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_conv_layer(base_model, model_name):\n",
    "    \n",
    "    models_ = get_models()\n",
    "    layer = base_model.get_layer(models_[model_name][\"last_conv_layer\"])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "base_model_class = getattr(\n",
    "    importlib.import_module(\n",
    "        f\"keras.applications.{models_[model_name]['module_name']}\"\n",
    "        ),\n",
    "        model_name)\n",
    "          \n",
    "img_input = Input(shape = input_shape)\n",
    "        \n",
    "base_model = base_model_class(\n",
    "            include_top = False,\n",
    "            input_tensor = img_input,\n",
    "            input_shape = input_shape,\n",
    "            weights = \"imagenet\",\n",
    "            pooling = \"avg\")\n",
    "\n",
    "if (model_name == \"DenseNet121\") & use_chex_weights:\n",
    "    \n",
    "    chex_weights_path = 'brucechou1983_CheXNet_Keras_0.3.0_weights.h5'\n",
    "    out = Dense(14, activation='sigmoid')(base_model.output)\n",
    "    base_model = Model(inputs=base_model.input, outputs=out)\n",
    "    base_model.load_weights(chex_weights_path)\n",
    "    x = get_last_conv_layer(base_model, model_name).output\n",
    "    output = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "else:\n",
    "    x = get_last_conv_layer(base_model, model_name).output\n",
    "    output = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f322929-aa2d-4eab-b118-3a1d4bad14f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d1e12ffb-b877-4a30-a9e6-db2e7ebe1a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "if use_fine_tuning:   \n",
    "    base_model.trainable = True\n",
    "    \n",
    "    if classification_type == \"multi\":\n",
    "        predictions = Dense(len(df_train.study_label.unique()), activation = \"softmax\", name = \"multi_predictions\")(output)\n",
    "        model = Model(base_model.input, predictions)\n",
    "        model.compile(Adam(lr=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "        \n",
    "    else:\n",
    "        predictions = Dense(len(df_train.image_label.unique()), activation = \"softmax\", name = \"binary_predictions\")(output)\n",
    "        model = Model(base_model.input, predictions)\n",
    "        model.compile(Adam(lr=learning_rate),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "        \n",
    "    if show_model_summary:\n",
    "        print(model.summary())\n",
    "        \n",
    "    # Keras callbacks\n",
    "    rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = verbose, \n",
    "                                    min_delta = 1e-4, min_lr = min_learning_rate, mode = 'min')\n",
    "    \n",
    "    es = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n",
    "                        restore_best_weights = True, verbose = verbose)\n",
    "    \n",
    "    ckp = ModelCheckpoint('model.h5',monitor = 'val_loss',\n",
    "                          verbose = verbose, save_best_only = True, mode = 'min')\n",
    "    \n",
    "    # Model fitting\n",
    "    history = model.fit(\n",
    "          train_generator,\n",
    "          epochs= epochs,\n",
    "          validation_data=valid_generator,\n",
    "          callbacks=[es, rlr, ckp],\n",
    "          verbose= verbose\n",
    "          )\n",
    "    \n",
    "    if save_weights:\n",
    "        model.save_weights(f\"{model_name}-model.h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd8f75-749c-473f-aa72-5810059e95b9",
   "metadata": {},
   "source": [
    "#### Feature Layer for SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "34fd8023-0759-4279-9e0e-d6a9eb43f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(feature_number, activation=LeakyReLU(alpha=0.2), name = \"features\")(output)\n",
    "model = Model(base_model.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "48c875c2-fd76-41c3-b64d-a2b133cd476f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames.\n",
      "Found 946 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "def generate_images_for_feature_extraction(classifier, classification_type, img_process_function, df_train, df_test, img_dir, img_size, batch_size, validation_split = 0.15):\n",
    "\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    \n",
    "    from skimage import exposure\n",
    "    \n",
    "    # Defined image preprocessing functions\n",
    "\n",
    "    def preprocess_function(img):\n",
    "        \n",
    "        if img_process_function == \"equalize_adapthist\":\n",
    "            img = exposure.equalize_adapthist(img/255, clip_limit=0.03, kernel_size=24)\n",
    "        elif img_process_function == \"equalize_hist\":\n",
    "            img = exposure.equalize_hist(img/255, clip_limit=0.03, kernel_size=24)\n",
    "        elif img_process_function == \"rescale_intensity\":\n",
    "            img = exposure.rescale_intensity(img/255, clip_limit=0.03, kernel_size=24)\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    \n",
    "    if classification_type == \"binary\":\n",
    "        y_col = \"image_label\"\n",
    "    else:\n",
    "        y_col = \"study_label\"\n",
    "    \n",
    "    \n",
    "    image_generator_train = ImageDataGenerator(preprocessing_function=preprocess_function,\n",
    "                                               validation_split=validation_split)\n",
    "        \n",
    "    image_generator_test = ImageDataGenerator(validation_split=validation_split,\n",
    "                                               preprocessing_function=preprocess_function)\n",
    "      \n",
    "\n",
    "    train_generator = image_generator_train.flow_from_dataframe(\n",
    "            dataframe = df_train,\n",
    "            directory=img_dir,\n",
    "            x_col = 'id',\n",
    "            y_col =  y_col,  \n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            seed = 42, \n",
    "            class_mode = \"raw\") \n",
    "    \n",
    "    test_generator = image_generator_test.flow_from_dataframe(\n",
    "            dataframe = df_test,\n",
    "            directory=img_dir,\n",
    "            x_col = 'id',\n",
    "            y_col = y_col,\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,  \n",
    "            seed=42, \n",
    "            class_mode = \"raw\")\n",
    "    \n",
    "    return train_generator, test_generator\n",
    "\n",
    "train_generator, test_generator = generate_images_for_feature_extraction( classifier = classifier, \n",
    "                                                                           classification_type = classification_type, \n",
    "                                                                           img_process_function = img_process_function, \n",
    "                                                                           df_train = df_train, \n",
    "                                                                           df_test = df_test, \n",
    "                                                                           img_dir = img_dir, \n",
    "                                                                           img_size = img_size, \n",
    "                                                                           batch_size = batch_size, \n",
    "                                                                           validation_split = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cdeb6f-7272-4219-9b4d-989d10cbce9c",
   "metadata": {},
   "source": [
    "#### Prepare Images for SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dc226ef2-340e-4b26-b8d3-8a94851407fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images_for_SVM(train_generator, test_generator, train_num, val_num):\n",
    "\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    for i in range(train_num):\n",
    "        x, y = next(train_generator)\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "            \n",
    "    args = (x_list[i] for i in range(train_num))\n",
    "    x_tr = np.vstack((args))\n",
    "    args = (y_list[i] for i in range(train_num))\n",
    "    y_tr = np.vstack(args)\n",
    "    y_tr = y_tr.ravel()\n",
    "            \n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    for i in range(val_num):\n",
    "        x, y = next(test_generator)\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "                \n",
    "    args = (x_list[i] for i in range(val_num))\n",
    "    x_val = np.vstack((args))\n",
    "    args = (y_list[i] for i in range(val_num))\n",
    "    y_val = np.vstack(args)\n",
    "    y_val = y_val.ravel()\n",
    "            \n",
    "    return x_tr, x_val, y_tr, y_val\n",
    "\n",
    "x_tr, x_val, y_tr, y_val = prepare_images_for_SVM(train_generator, test_generator, train_num, val_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af31111-a9f7-45c4-b5f2-b94ff22a58b2",
   "metadata": {},
   "source": [
    "#### Extracts Features from Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "894c1109-b364-46fe-93a8-b220ba2b1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_images(model, x_tr, x_val, y_tr, y_val):\n",
    "        \n",
    "    x_train = model.predict(x_tr)\n",
    "    x_test = model.predict(x_val)\n",
    "    y_train = y_tr\n",
    "    y_test = y_val\n",
    "        \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# Extract feature vectors\n",
    "x_train, x_test, y_train, y_test = extract_features_from_images(model, x_tr, x_val, y_tr, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1140cc5-65dc-413f-ab41-d5e1eb9bc6fe",
   "metadata": {},
   "source": [
    "#### Print feature vectors' shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c3f41fd-bb15-4764-badf-223c3af13b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data shapes from transfer network\n",
      "x_train shape:  (250, 128)\n",
      "x_test shape:  (50, 128)\n",
      "y_train shape:  (250,)\n",
      "y_test shape:  (50,)\n"
     ]
    }
   ],
   "source": [
    "def print_feature_shapes(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    print(\"Extracted data shapes from transfer network\")\n",
    "    print(\"x_train shape: \",x_train.shape)\n",
    "    print(\"x_test shape: \",x_test.shape)\n",
    "    print(\"y_train shape: \",y_train.shape)\n",
    "    print(\"y_test shape: \",y_test.shape)\n",
    "    \n",
    "print_feature_shapes(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239646fe-3854-47fb-a28e-32ee7a490015",
   "metadata": {},
   "source": [
    "#### Fit SVM cv models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09d5f746-52fb-49ec-8d58-fdc2bb95c9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    }
   ],
   "source": [
    "def fit_cross_models(x_train, x_test, y_train, y_test, svm_hyp_search):\n",
    "    \n",
    "    if svm_hyp_search == \"grid\":\n",
    "        \n",
    "        svc_param_grid = {\"kernel\" : [\"rbf\", \"poly\", \"linear\"],\n",
    "                          \"gamma\": [0.001, 0.01, 0.1, 1],\n",
    "                          \"C\": [1,10,50,100,200,300]}\n",
    "        \n",
    "        clf = GridSearchCV(SVC(random_state = 42), param_grid = svc_param_grid, \n",
    "                           cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", \n",
    "                           n_jobs = -1,verbose = 1)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        from skopt import BayesSearchCV\n",
    "        \n",
    "        # log-uniform: understand as search over p = exp(x) by varying x\n",
    "        \n",
    "        search_spaces = {\n",
    "                        'C': (1e-4, 1e+4, 'log-uniform'),\n",
    "                        'gamma': (1e-4, 1e+4, 'log-uniform'),\n",
    "                        'degree': (1, 8),  # integer valued parameter\n",
    "                        'kernel': ['linear', 'poly', 'rbf'],  # categorical parameter\n",
    "                        }\n",
    "        \n",
    "        clf = BayesSearchCV(\n",
    "            SVC(random_state = 42),\n",
    "            search_spaces=search_spaces,\n",
    "            n_iter=32,\n",
    "            cv=3)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "        \n",
    "    svc = clf.best_estimator_\n",
    "    svc.fit(x_train, y_train)\n",
    "    y_pred = svc.predict(x_test)\n",
    "    \n",
    "    return clf, svc, y_pred\n",
    "\n",
    "clf, svc, y_pred = fit_cross_models(x_train, x_test, y_train, y_test, svm_hyp_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ccd51a1b-0547-4a2e-9303-c1486a806238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM estimator (parameters):  SVC(C=10, gamma=0.1, kernel='poly', random_state=42)\n",
      "SVM Best Train accuracy 0.888\n",
      "SVM Best Test Accuracy 0.7\n"
     ]
    }
   ],
   "source": [
    "# Prints best SVM scores and estimator\n",
    "    \n",
    "def print_best_results(clf, svc, x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    train_accuracy = svc.score(x_train, y_train)\n",
    "    test_accuracy = svc.score(x_test, y_test)\n",
    "    \n",
    "    print(\"Best SVM estimator (parameters): \", clf.best_estimator_)\n",
    "    print(\"SVM Best Train accuracy\",train_accuracy)\n",
    "    print(\"SVM Best Test Accuracy\",test_accuracy)\n",
    "    \n",
    "print_best_results(clf, svc, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a432ec1-9f01-4f0e-9f19-8b9ce360886e",
   "metadata": {},
   "source": [
    "#### If wanted, plots cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3f84608f-047a-4682-ac8c-b01eb0fdb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if svm_hyp_search == \"grid\":\n",
    "    def plot_cv_splits(clf, number_of_top = 7):\n",
    "\n",
    "        results_df = pd.DataFrame(clf.cv_results_)\n",
    "        results_df = results_df.sort_values(by=['rank_test_score'])\n",
    "        results_df = (\n",
    "            results_df\n",
    "            .set_index(results_df[\"params\"].apply(\n",
    "                lambda x: \"_\".join(str(val) for val in x.values()))\n",
    "            )\n",
    "            .rename_axis('kernel')\n",
    "        )\n",
    "\n",
    "        # create df of model scores ordered by performance\n",
    "\n",
    "        model_scores = results_df.filter(regex=r'split\\d*_test_score')\n",
    "        model_scores = model_scores.transpose().iloc[:30,:number_of_top]\n",
    "\n",
    "        # plot 30 examples of dependency between cv fold and AUC scores\n",
    "\n",
    "        plt.subplots(figsize = (8,12))\n",
    "        sns.lineplot(\n",
    "            data=model_scores,\n",
    "            dashes=False, palette='Set1', marker='o', alpha=.5\n",
    "        )\n",
    "        plt.xlabel(\"CV test fold\")\n",
    "        plt.ylabel(\"Model AUC\")\n",
    "        plt.xticks(rotation = 45)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_cv_scores(clf, max_rank = 10):\n",
    "\n",
    "        cv_results = pd.DataFrame(clf.cv_results_)\n",
    "        cv_results = cv_results[\n",
    "            ['params', 'rank_test_score', 'mean_test_score', 'std_test_score']\n",
    "        ]\n",
    "        cv_results = cv_results[cv_results['rank_test_score'] < max_rank]\n",
    "\n",
    "        cv_results = (\n",
    "            cv_results\n",
    "            .set_index(cv_results[\"params\"].apply(\n",
    "                lambda x: \"_\".join(str(val) for val in x.values()))\n",
    "            )\n",
    "            .rename_axis('kernel')\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize = (10,8))\n",
    "        sns.lineplot(data=cv_results['mean_test_score'])\n",
    "        plt.xticks(rotation = 45)\n",
    "        plt.xlabel(\"Parameters\")\n",
    "        plt.ylabel(\"Mean test score\")\n",
    "        plt.show()\n",
    "\n",
    "    if show_cv_scores:\n",
    "        plot_cv_splits(clf, number_of_top = 7)\n",
    "        plot_cv_scores(clf, max_rank = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab560d7-5f6c-4d2f-b47c-bd7f740b781d",
   "metadata": {},
   "source": [
    "#### Shows confusion matrix for SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9a8957e-8414-4104-947b-a5b6db337bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_svm_confusion_matrix(svc, x_test, y_test):\n",
    "    \n",
    "    actual =  y_test\n",
    "    preds = svc.predict(x_test)\n",
    "    cfmx = confusion_matrix(actual, preds)\n",
    "    acc = accuracy_score(actual, preds)    \n",
    "    \n",
    "    plt.figure()\n",
    "    sns.heatmap(cfmx, annot=True, cmap='plasma',\n",
    "        xticklabels=list(np.unique(y_test)),\n",
    "            fmt='.0f', \n",
    "            yticklabels=list(np.unique(y_test))\n",
    "            )\n",
    "    plt.xlabel(\"Predictions\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_svm_confusion_matrix(svc, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a778fd-1570-47d5-9b17-d60f559f7c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
