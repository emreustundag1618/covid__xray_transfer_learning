{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ee0635-c0de-43d1-b795-4437c44ed754",
   "metadata": {},
   "source": [
    "## SIIM Data Covid-19 SVM classifier\n",
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3afcf9d8-304e-420b-b146-6484220986e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default config\n",
    "model_name = \"ResNet50\"\n",
    "learning_rate = 0.0001\n",
    "min_learning_rate = 1e-8\n",
    "batch_size = 25\n",
    "epochs = 1\n",
    "verbose = 1\n",
    "img_process_function = \"equalize_adapthist\"\n",
    "isKaggleData = False\n",
    "classification_type = \"binary\"\n",
    "classifier = \"svm\"\n",
    "\n",
    "train_num = 150 / batch_size\n",
    "val_num = 50 / batch_size\n",
    "show_cv_scores = False\n",
    "feature_number = 64\n",
    "\n",
    "use_fine_tuning = True\n",
    "use_chex_weights = True\n",
    "\n",
    "libraries = [\"pandas\",\"numpy\",\"sklearn\",\"tensorflow\",\"keras\",\"skimage\",\"matplotlib\",\"seaborn\"]\n",
    "show_versions = True\n",
    "svm_hyp_search = \"bayes\"\n",
    "\n",
    "show_model_summary = False\n",
    "save_weights = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940df0b8-6216-4555-b552-f7230b33c171",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb1aaa7-59d2-495f-afbb-3191d8fbd84d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from skimage import exposure\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint,  EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications import VGG16, VGG19, InceptionV3, NASNetMobile, NASNetLarge, DenseNet121, ResNet50, Xception, InceptionResNetV2\n",
    "\n",
    "import importlib\n",
    "from skimage import exposure\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb37226f-4eaf-4d67-9d33-ff3fbaf04de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.2.4\n",
      "numpy version: 1.19.2\n",
      "sklearn version: 0.24.1\n",
      "tensorflow version: 2.3.0\n",
      "keras version: 2.4.3\n",
      "skimage version: 0.18.1\n",
      "matplotlib version: 3.3.4\n",
      "seaborn version: 0.11.1\n"
     ]
    }
   ],
   "source": [
    "def display_versions(libraries = None):\n",
    "    \n",
    "    from importlib import import_module\n",
    "    \n",
    "    for library in libraries:\n",
    "        print(f\"{library} version: {import_module(library).__version__}\")\n",
    "\n",
    "if show_versions:\n",
    "    display_versions(libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f649799-417e-4b5d-a534-758efd9468ab",
   "metadata": {},
   "source": [
    "#### Transfer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afc5133d-b708-49bc-94c4-21e24e11eb66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, VGG19, InceptionV3, NASNetMobile, NASNetLarge, DenseNet121, ResNet50, Xception, InceptionResNetV2\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    \n",
    "    models_ = dict(\n",
    "                    VGG16 = dict(\n",
    "                        input_shape = (224,224,3),\n",
    "                        module_name = \"vgg16\",\n",
    "                        last_conv_layer = \"block5_conv3\",\n",
    "                    ),\n",
    "                    VGG19 = dict(\n",
    "                        input_shape = (224,224,3),\n",
    "                        module_name = \"vgg19\",\n",
    "                        last_conv_layer = \"block5_conv4\",\n",
    "                    ),\n",
    "                    # this is used for ChexNet\n",
    "                    DenseNet121=dict(\n",
    "                        input_shape=(224, 224, 3),\n",
    "                        module_name=\"densenet\",\n",
    "                        last_conv_layer=\"conv5_block16_concat\",\n",
    "                    ),\n",
    "                    ResNet50=dict(\n",
    "                        input_shape=(224, 224, 3),\n",
    "                        module_name=\"resnet50\",\n",
    "                        last_conv_layer=\"conv5_block3_out\",\n",
    "                    ),\n",
    "                    InceptionV3=dict(\n",
    "                        input_shape=(299, 299, 3),\n",
    "                        module_name=\"inception_v3\",\n",
    "                        last_conv_layer=\"mixed10\",\n",
    "                    ),\n",
    "                    InceptionResNetV2=dict(\n",
    "                        input_shape=(299, 299, 3),\n",
    "                        module_name=\"inception_resnet_v2\",\n",
    "                        last_conv_layer=\"conv_7b_bn\",\n",
    "                    ),\n",
    "                    NASNetMobile=dict(\n",
    "                        input_shape=(224, 224, 3),\n",
    "                        module_name=\"nasnet\",\n",
    "                        last_conv_layer=\"normal_concat_12\",\n",
    "                    ),\n",
    "                    NASNetLarge=dict(\n",
    "                        input_shape=(331, 331, 3),\n",
    "                        module_name=\"nasnet\",\n",
    "                        last_conv_layer=\"normal_concat_18\",\n",
    "                    ),\n",
    "                    Xception=dict(\n",
    "                        input_shape=(299, 299, 3),\n",
    "                        module_name=\"xception\",\n",
    "                        last_conv_layer=\"block14_sepconv2_act\",\n",
    "                    ),\n",
    "                \n",
    "                )\n",
    "    \n",
    "    return models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca22c001-0526-473a-b17a-91396bbb818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ = get_models()\n",
    "input_shape = models_[model_name][\"input_shape\"]\n",
    "img_size = input_shape[0]\n",
    "\n",
    "\n",
    "if isKaggleData:\n",
    "    data, img_dir = prepare_data_for_kaggle()\n",
    "else:\n",
    "    data = pd.read_csv(\"../train_data.csv\")\n",
    "    img_dir = \"../images/train\"\n",
    "    \n",
    "df_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f771ca7-465b-401f-841a-7b8e5f3b4bad",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f78b9d0c-54a5-48c2-989f-16bd396f9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop images from dataframe not in images directory\n",
    "files = os.listdir(\"../images/train\")\n",
    "\n",
    "not_in_files_index = []\n",
    "\n",
    "for file_id in df_data.id:\n",
    "    if file_id in files:\n",
    "        continue\n",
    "    else:\n",
    "        not_in_files_index.append(df_data[df_data[\"id\"] == file_id].index[0])\n",
    "        \n",
    "df_data = df_data.drop(not_in_files_index, axis = 0)\n",
    "\n",
    "# drop images that have unclear view\n",
    "drop_df = pd.read_csv(\"../dropped_image_IDs.csv\") + \".jpg\"\n",
    "\n",
    "drop_index = []\n",
    "for row in drop_df.values:\n",
    "    drop_index.append(df_data[df_data[\"id\"] == row[0]].index[0])\n",
    "    \n",
    "df_data = df_data.drop(drop_index, axis = 0)\n",
    "\n",
    "# splitting images train and test\n",
    "df_train = df_data.iloc[:5000]\n",
    "df_test = df_data.iloc[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a3f3e-86db-46ce-b6f0-c64187dc66a9",
   "metadata": {},
   "source": [
    "#### Image Generators for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb5019ad-f74d-47ce-b77b-3a1d46fbcf03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4250 validated image filenames belonging to 2 classes.\n",
      "Found 750 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "def generate_images_for_model_training(classifier, classification_type, img_process_function, df_train, df_test, img_dir, img_size, batch_size, validation_split = 0.15):\n",
    "    \n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    \n",
    "    from skimage import exposure\n",
    "    \n",
    "    # Defined image preprocessing functions\n",
    "\n",
    "    def preprocess_function(img):\n",
    "        \n",
    "        if img_process_function == \"equalize_adapthist\":\n",
    "            img = exposure.equalize_adapthist(img/255, clip_limit=0.03, kernel_size=24)\n",
    "        elif img_process_function == \"equalize_hist\":\n",
    "            img = exposure.equalize_hist(img/255, clip_limit=0.03, kernel_size=24)\n",
    "        elif img_process_function == \"rescale_intensity\":\n",
    "            img = exposure.rescale_intensity(img/255, clip_limit=0.03, kernel_size=24)\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    if classification_type == \"binary\":\n",
    "        y_col = \"image_label\"\n",
    "    else:\n",
    "        y_col = \"study_label\"\n",
    "    \n",
    "    \n",
    "    image_generator_train = ImageDataGenerator(\n",
    "                    featurewise_center=False,\n",
    "                    samplewise_center=False,\n",
    "                    featurewise_std_normalization=False,\n",
    "                    samplewise_std_normalization=False,\n",
    "                    zca_epsilon=1e-06,\n",
    "                    zca_whitening=False,\n",
    "                    width_shift_range=0.0,\n",
    "                    height_shift_range=0.0,\n",
    "                    brightness_range=[0.8, 1.1],\n",
    "                    shear_range=0.1,\n",
    "                    zoom_range=0.0,\n",
    "                    channel_shift_range=0.0,\n",
    "                    cval=0.0,\n",
    "                    horizontal_flip=False,\n",
    "                    vertical_flip=False,\n",
    "                    rescale=None,\n",
    "                    rotation_range=20,\n",
    "                    preprocessing_function=preprocess_function,\n",
    "                    validation_split=validation_split)\n",
    "        \n",
    "    image_generator_valid = ImageDataGenerator(validation_split=validation_split,\n",
    "                                               preprocessing_function=preprocess_function)\n",
    "      \n",
    "\n",
    "    train_generator = image_generator_train.flow_from_dataframe(\n",
    "                dataframe = df_train,\n",
    "                directory=img_dir,\n",
    "                x_col = 'id',\n",
    "                y_col =  y_col,  \n",
    "                target_size=(img_size, img_size),\n",
    "                batch_size=batch_size,\n",
    "                subset='training', \n",
    "                seed = 42, \n",
    "                class_mode = \"categorical\") \n",
    "        \n",
    "    valid_generator = image_generator_valid.flow_from_dataframe(\n",
    "            dataframe = df_train,\n",
    "            directory=img_dir,\n",
    "            x_col = 'id',\n",
    "            y_col = y_col,\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            subset='validation', \n",
    "            shuffle=False,  \n",
    "            seed=42, \n",
    "            class_mode = \"categorical\")\n",
    "    \n",
    "    return train_generator, valid_generator\n",
    "\n",
    "train_generator, valid_generator = generate_images_for_model_training( classifier = classifier, \n",
    "                                                                       classification_type = classification_type, \n",
    "                                                                       img_process_function = img_process_function, \n",
    "                                                                       df_train = df_train, \n",
    "                                                                       df_test = df_test, \n",
    "                                                                       img_dir = img_dir, \n",
    "                                                                       img_size = img_size, \n",
    "                                                                       batch_size = batch_size, \n",
    "                                                                       validation_split = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a1cbc-c9b2-41d8-aa44-f7c83ab1364f",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eca7506a-5eed-459f-976d-73f9b3e6b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_conv_layer(base_model, model_name):\n",
    "    \n",
    "    models_ = get_models()\n",
    "    layer = base_model.get_layer(models_[model_name][\"last_conv_layer\"])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "base_model_class = getattr(\n",
    "    importlib.import_module(\n",
    "        f\"keras.applications.{models_[model_name]['module_name']}\"\n",
    "        ),\n",
    "        model_name)\n",
    "          \n",
    "img_input = Input(shape = input_shape)\n",
    "        \n",
    "base_model = base_model_class(\n",
    "            include_top = False,\n",
    "            input_tensor = img_input,\n",
    "            input_shape = input_shape,\n",
    "            weights = \"imagenet\",\n",
    "            pooling = \"avg\")\n",
    "\n",
    "if (model_name == \"DenseNet121\") & use_chex_weights:\n",
    "    \n",
    "    chex_weights_path = 'brucechou1983_CheXNet_Keras_0.3.0_weights.h5'\n",
    "    out = Dense(14, activation='sigmoid')(base_model.output)\n",
    "    base_model = Model(inputs=base_model.input, outputs=out)\n",
    "    base_model.load_weights(chex_weights_path)\n",
    "    x = get_last_conv_layer(base_model, model_name).output\n",
    "    output = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "else:\n",
    "    x = get_last_conv_layer(base_model, model_name).output\n",
    "    output = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f322929-aa2d-4eab-b118-3a1d4bad14f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e12ffb-b877-4a30-a9e6-db2e7ebe1a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/170 [>.............................] - ETA: 31:30 - loss: 0.7072 - accuracy: 0.6000"
     ]
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "\n",
    "if use_fine_tuning:   \n",
    "    base_model.trainable = True\n",
    "    \n",
    "    if classification_type == \"multi\":\n",
    "        predictions = Dense(len(df_train.study_label.unique()), activation = \"softmax\", name = \"multi_predictions\")(output)\n",
    "        model = Model(base_model.input, predictions)\n",
    "        model.compile(Adam(lr=learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "        \n",
    "    else:\n",
    "        predictions = Dense(len(df_train.image_label.unique()), activation = \"softmax\", name = \"binary_predictions\")(output)\n",
    "        model = Model(base_model.input, predictions)\n",
    "        model.compile(Adam(lr=learning_rate),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "        \n",
    "    if show_model_summary:\n",
    "        print(model.summary())\n",
    "        \n",
    "    # Keras callbacks\n",
    "    rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = verbose, \n",
    "                                    min_delta = 1e-4, min_lr = min_learning_rate, mode = 'min')\n",
    "    \n",
    "    es = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n",
    "                        restore_best_weights = True, verbose = verbose)\n",
    "    \n",
    "    ckp = ModelCheckpoint('model.h5',monitor = 'val_loss',\n",
    "                          verbose = verbose, save_best_only = True, mode = 'min')\n",
    "    \n",
    "    # Model fitting\n",
    "    history = model.fit(\n",
    "          train_generator,\n",
    "          epochs= epochs,\n",
    "          validation_data=valid_generator,\n",
    "          callbacks=[es, rlr, ckp],\n",
    "          verbose= verbose\n",
    "          )\n",
    "    \n",
    "    if save_weights:\n",
    "        model.save_weights(f\"{model_name}-model.h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd8f75-749c-473f-aa72-5810059e95b9",
   "metadata": {},
   "source": [
    "#### Feature Layer for SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd8023-0759-4279-9e0e-d6a9eb43f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(feature_number, activation=LeakyReLU(alpha=0.2), name = \"features\")(output)\n",
    "model = Model(base_model.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c875c2-fd76-41c3-b64d-a2b133cd476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images_for_feature_extraction(classifier, classification_type, img_process_function, df_train, df_test, img_dir, img_size, batch_size, validation_split = 0.15):\n",
    "\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    \n",
    "    from skimage import exposure\n",
    "    \n",
    "    # Defined image preprocessing functions\n",
    "\n",
    "    def preprocess_function(img):\n",
    "        \n",
    "        if img_process_function == \"equalize_adapthist\":\n",
    "            img = exposure.equalize_adapthist(img/255, clip_limit=0.03, kernel_size=24)\n",
    "        elif img_process_function == \"equalize_hist\":\n",
    "            img = exposure.equalize_hist(img/255, clip_limit=0.03, kernel_size=24)\n",
    "        elif img_process_function == \"rescale_intensity\":\n",
    "            img = exposure.rescale_intensity(img/255, clip_limit=0.03, kernel_size=24)\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    \n",
    "    if classification_type == \"binary\":\n",
    "        y_col = \"image_label\"\n",
    "    else:\n",
    "        y_col = \"study_label\"\n",
    "    \n",
    "    \n",
    "    image_generator_train = ImageDataGenerator(preprocessing_function=preprocess_function,\n",
    "                                               validation_split=validation_split)\n",
    "        \n",
    "    image_generator_test = ImageDataGenerator(validation_split=validation_split,\n",
    "                                               preprocessing_function=preprocess_function)\n",
    "      \n",
    "\n",
    "    train_generator = image_generator_train.flow_from_dataframe(\n",
    "            dataframe = df_train,\n",
    "            directory=img_dir,\n",
    "            x_col = 'id',\n",
    "            y_col =  y_col,  \n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            seed = 42, \n",
    "            class_mode = \"raw\") \n",
    "    \n",
    "    test_generator = image_generator_test.flow_from_dataframe(\n",
    "            dataframe = df_test,\n",
    "            directory=img_dir,\n",
    "            x_col = 'id',\n",
    "            y_col = y_col,\n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,  \n",
    "            seed=42, \n",
    "            class_mode = \"raw\")\n",
    "    \n",
    "    return train_generator, test_generator\n",
    "\n",
    "train_generator, test_generator = generate_images_for_feature_extraction( classifier = classifier, \n",
    "                                                                           classification_type = classification_type, \n",
    "                                                                           img_process_function = img_process_function, \n",
    "                                                                           df_train = df_train, \n",
    "                                                                           df_test = df_test, \n",
    "                                                                           img_dir = img_dir, \n",
    "                                                                           img_size = img_size, \n",
    "                                                                           batch_size = batch_size, \n",
    "                                                                           validation_split = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cdeb6f-7272-4219-9b4d-989d10cbce9c",
   "metadata": {},
   "source": [
    "#### Prepare Images for SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc226ef2-340e-4b26-b8d3-8a94851407fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images_for_SVM(train_generator, test_generator, train_num, val_num):\n",
    "\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    for i in range(train_num):\n",
    "        x, y = next(train_generator)\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "            \n",
    "    args = (x_list[i] for i in range(train_num))\n",
    "    x_tr = np.vstack((args))\n",
    "    args = (y_list[i] for i in range(train_num))\n",
    "    y_tr = np.vstack(args)\n",
    "    y_tr = y_tr.ravel()\n",
    "            \n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    for i in range(val_num):\n",
    "        x, y = next(test_generator)\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "                \n",
    "    args = (x_list[i] for i in range(val_num))\n",
    "    x_val = np.vstack((args))\n",
    "    args = (y_list[i] for i in range(val_num))\n",
    "    y_val = np.vstack(args)\n",
    "    y_val = y_val.ravel()\n",
    "            \n",
    "    return x_tr, x_val, y_tr, y_val\n",
    "\n",
    "x_tr, x_val, y_tr, y_val = prepare_images_for_SVM(train_generator, test_generator, train_num, val_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af31111-a9f7-45c4-b5f2-b94ff22a58b2",
   "metadata": {},
   "source": [
    "#### Extracts Features from Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c1109-b364-46fe-93a8-b220ba2b1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_images(model, x_tr, x_val, y_tr, y_val):\n",
    "        \n",
    "    x_train = model.predict(x_tr)\n",
    "    x_test = model.predict(x_val)\n",
    "    y_train = y_tr\n",
    "    y_test = y_val\n",
    "        \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# Extract feature vectors\n",
    "x_train, x_test, y_train, y_test = extract_features_from_images(model, x_tr, x_val, y_tr, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1140cc5-65dc-413f-ab41-d5e1eb9bc6fe",
   "metadata": {},
   "source": [
    "#### Print feature vectors' shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f41fd-bb15-4764-badf-223c3af13b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_shapes(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    print(\"Extracted data shapes from transfer network\")\n",
    "    print(\"x_train shape: \",x_train.shape)\n",
    "    print(\"x_test shape: \",x_test.shape)\n",
    "    print(\"y_train shape: \",y_train.shape)\n",
    "    print(\"y_test shape: \",y_test.shape)\n",
    "    \n",
    "print_feature_shapes(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239646fe-3854-47fb-a28e-32ee7a490015",
   "metadata": {},
   "source": [
    "#### Fit SVM cv models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5f746-52fb-49ec-8d58-fdc2bb95c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cross_models(x_train, x_test, y_train, y_test, svm_hyp_search):\n",
    "    \n",
    "    if svm_hyp_search == \"grid\":\n",
    "        \n",
    "        svc_param_grid = {\"kernel\" : [\"rbf\", \"poly\", \"linear\"],\n",
    "                          \"gamma\": [0.001, 0.01, 0.1, 1],\n",
    "                          \"C\": [1,10,50,100,200,300]}\n",
    "        \n",
    "        clf = GridSearchCV(SVC(random_state = 42), param_grid = svc_param_grid, \n",
    "                           cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", \n",
    "                           n_jobs = -1,verbose = 1)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        from skopt import BayesSearchCV\n",
    "        \n",
    "        # log-uniform: understand as search over p = exp(x) by varying x\n",
    "        \n",
    "        search_spaces = {\n",
    "                        'C': (1e-3, 1e+3, 'log-uniform'),\n",
    "                        'gamma': (1e-3, 1e+3, 'log-uniform'),\n",
    "                        'degree': (1, 4),  # integer valued parameter\n",
    "                        'kernel': ['linear', 'poly', 'rbf'],  # categorical parameter\n",
    "                        }\n",
    "        \n",
    "        clf = BayesSearchCV(\n",
    "            SVC(random_state = 42),\n",
    "            search_spaces=search_spaces,\n",
    "            n_iter=16,\n",
    "            cv=5)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "        \n",
    "    svc = clf.best_estimator_\n",
    "    svc.fit(x_train, y_train)\n",
    "    y_pred = svc.predict(x_test)\n",
    "    \n",
    "    return clf, svc, y_pred\n",
    "\n",
    "clf, svc, y_pred = fit_cross_models(x_train, x_test, y_train, y_test, svm_hyp_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd51a1b-0547-4a2e-9303-c1486a806238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints best SVM scores and estimator\n",
    "    \n",
    "def print_best_results(clf, svc, x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    train_accuracy = svc.score(x_train, y_train)\n",
    "    test_accuracy = svc.score(x_test, y_test)\n",
    "    \n",
    "    print(\"Best SVM estimator (parameters): \", clf.best_estimator_)\n",
    "    print(\"SVM Best Train accuracy\",train_accuracy)\n",
    "    print(\"SVM Best Test Accuracy\",test_accuracy)\n",
    "    \n",
    "print_best_results(clf, svc, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a432ec1-9f01-4f0e-9f19-8b9ce360886e",
   "metadata": {},
   "source": [
    "#### If wanted, plots cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84608f-047a-4682-ac8c-b01eb0fdb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if svm_hyp_search == \"grid\":\n",
    "    def plot_cv_splits(clf, number_of_top = 7):\n",
    "\n",
    "        results_df = pd.DataFrame(clf.cv_results_)\n",
    "        results_df = results_df.sort_values(by=['rank_test_score'])\n",
    "        results_df = (\n",
    "            results_df\n",
    "            .set_index(results_df[\"params\"].apply(\n",
    "                lambda x: \"_\".join(str(val) for val in x.values()))\n",
    "            )\n",
    "            .rename_axis('kernel')\n",
    "        )\n",
    "\n",
    "        # create df of model scores ordered by performance\n",
    "\n",
    "        model_scores = results_df.filter(regex=r'split\\d*_test_score')\n",
    "        model_scores = model_scores.transpose().iloc[:30,:number_of_top]\n",
    "\n",
    "        # plot 30 examples of dependency between cv fold and AUC scores\n",
    "\n",
    "        plt.subplots(figsize = (8,12))\n",
    "        sns.lineplot(\n",
    "            data=model_scores,\n",
    "            dashes=False, palette='Set1', marker='o', alpha=.5\n",
    "        )\n",
    "        plt.xlabel(\"CV test fold\")\n",
    "        plt.ylabel(\"Model AUC\")\n",
    "        plt.xticks(rotation = 45)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_cv_scores(clf, max_rank = 10):\n",
    "\n",
    "        cv_results = pd.DataFrame(clf.cv_results_)\n",
    "        cv_results = cv_results[\n",
    "            ['params', 'rank_test_score', 'mean_test_score', 'std_test_score']\n",
    "        ]\n",
    "        cv_results = cv_results[cv_results['rank_test_score'] < max_rank]\n",
    "\n",
    "        cv_results = (\n",
    "            cv_results\n",
    "            .set_index(cv_results[\"params\"].apply(\n",
    "                lambda x: \"_\".join(str(val) for val in x.values()))\n",
    "            )\n",
    "            .rename_axis('kernel')\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize = (10,8))\n",
    "        sns.lineplot(data=cv_results['mean_test_score'])\n",
    "        plt.xticks(rotation = 45)\n",
    "        plt.xlabel(\"Parameters\")\n",
    "        plt.ylabel(\"Mean test score\")\n",
    "        plt.show()\n",
    "\n",
    "    if show_cv_scores:\n",
    "        plot_cv_splits(clf, number_of_top = 7)\n",
    "        plot_cv_scores(clf, max_rank = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab560d7-5f6c-4d2f-b47c-bd7f740b781d",
   "metadata": {},
   "source": [
    "#### Shows confusion matrix for SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8957e-8414-4104-947b-a5b6db337bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svm_confusion_matrix(svc, x_test, y_test):\n",
    "    \n",
    "    actual =  y_test\n",
    "    preds = svc.predict(x_test)\n",
    "    cfmx = confusion_matrix(actual, preds)\n",
    "    acc = accuracy_score(actual, preds)    \n",
    "    \n",
    "    plt.figure()\n",
    "    sns.heatmap(cfmx, annot=True, cmap='plasma',\n",
    "        xticklabels=list(np.unique(y_test)),\n",
    "            fmt='.0f', \n",
    "            yticklabels=list(np.unique(y_test))\n",
    "            )\n",
    "    plt.xlabel(\"Predictions\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()\n",
    "    \n",
    "# plot_svm_confusion_matrix(svc, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a778fd-1570-47d5-9b17-d60f559f7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual =  test_generator.labels\n",
    "preds = np.argmax(model.predict(test_generator), axis=1)\n",
    "cfmx = confusion_matrix(actual, preds)\n",
    "\n",
    "sns.heatmap(cfmx, annot=True, cmap='Blues',\n",
    "    xticklabels=list(test_generator.class_indices.keys()),\n",
    "        fmt='.0f', \n",
    "        yticklabels=list(test_generator.class_indices.keys())\n",
    "        )\n",
    "\n",
    "plt.xlabel(\"Predictions\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n",
    "\n",
    "acc = accuracy_score(actual, preds)\n",
    "f1 = f1_score(actual, preds, average = \"micro\")\n",
    "prec = precision_score(actual, preds, average = \"micro\")\n",
    "rec = recall_score(actual, preds, average = \"micro\")\n",
    "\n",
    "print(\"Results:\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Model name:\",model_name)\n",
    "print(\"Classification type:\",classification_type)\n",
    "print(\"Classifier:\",classifier)\n",
    "print(\"Image preprocess function:\",img_process_function)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(\"Batch size:\",batch_size)\n",
    "print(\"Learning rate:\",learning_rate)\n",
    "print(\"Number of Epoch:\",epochs)\n",
    "\n",
    "if model_name == \"DenseNet121\":\n",
    "    print(\"Chexnet weights status:\",use_chex_weights)\n",
    "    \n",
    "print(\"Classification Metrics:\")\n",
    "print(\"-------------------------\")\n",
    "print(\"Accuracy: \",acc)\n",
    "print(\"F1 score:\",f1)\n",
    "print(\"Precision:\",prec)\n",
    "print(\"Recall:\",rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed67df-ead7-40a6-9daf-a15095e1feee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
